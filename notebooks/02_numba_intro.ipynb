{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Numba\n",
    "Now that we know how to profile functions, we're ready to improve their performance!\n",
    "\n",
    "## What is Numba?\n",
    "* A Just-in-time (JIT) compiler for user defined, Python functions.\n",
    "* Compiles python code to machine (binary) code, using the LLVM compiler.\n",
    "\n",
    "\n",
    "## How to use `numba` to improve performance.\n",
    "1. Identify the bottleneck function.\n",
    "2. Use the `jit` decorator to compile the function in machine code. \n",
    "3. That's it!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A naive example\n",
    "* In general, numba can optimize code when written in its most basic form.\n",
    "* We often need to write unrolled loops!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the average of an array, unrolled\n",
    "def average_unrolled(arr):\n",
    "    total = 0\n",
    "    for elem in arr:\n",
    "        total += elem\n",
    "    total /= len(arr)\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "arr = np.random.uniform(size=1000000)\n",
    "print(average_unrolled(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unrolled_time = %timeit -o average_unrolled(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, let's start with numba!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The simplest way to jit a function\n",
    "@jit\n",
    "def average_jitted(arr):\n",
    "    total = 0.0\n",
    "    for elem in arr:\n",
    "        total += elem\n",
    "    total /= len(arr)\n",
    "    return total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There's also an alternative, less common syntax. We will use it extensively in\n",
    "# this notebook because it's more compact.\n",
    "average_jitted = jit()(average_unrolled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_jitted(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jitted_time = %timeit -o average_jitted(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unrolled_time.average / jitted_time.average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The jitted version should be way faster than the unrolled version. \n",
    "\n",
    "What about numpy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit arr.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy at its core runs compiled, optimized and usually parallelized with MKL, code.\n",
    "\n",
    "Numba is best suited for compute intensive calculations.\n",
    "\n",
    "Let's see a more complex example from BLonD. This is the Energy `kick` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "# Unrolled version of the kick (simplified for 1 RF station)\n",
    "def kick_unrolled(dt, dE, voltage, omega, phi, acc_kick):\n",
    "    for i in range(len(dt)):\n",
    "        dE[i] += voltage * math.sin(omega * dt[i] + phi) + acc_kick\n",
    "\n",
    "# Numpy version of kick (simplified for 1 RF station)\n",
    "def kick_numpy(dt, dE, voltage, omega, phi, acc_kick):    \n",
    "    dE += voltage * np.sin(omega * dt + phi) + acc_kick\n",
    "\n",
    "# Random initialization of the necessary arrays\n",
    "dE = np.random.uniform(size=1000000)\n",
    "dt = np.random.uniform(size=1000000)\n",
    "voltage = float(np.random.uniform(size=1))\n",
    "phi = float(np.random.uniform(size=1))\n",
    "omega = float(np.random.uniform(size=1))\n",
    "acc_kick = float(np.random.uniform(size=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unrolled_kick_time = %timeit -o kick_unrolled(dt, dE, voltage, omega, phi, acc_kick)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_kick_time = %timeit -o kick_numpy(dt, dE, voltage, omega, phi, acc_kick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jitted_kick = jit()(kick_unrolled)\n",
    "jitted_kick_time = %timeit -o jitted_kick(dt, dE, voltage, omega, phi, acc_kick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_speedup = unrolled_kick_time.best / numpy_kick_time.best\n",
    "jit_speedup = unrolled_kick_time.best / jitted_kick_time.best\n",
    "print(f'Numpy speedup: {numpy_speedup:.2f}')\n",
    "print(f'Jit Speedup: {jit_speedup:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diving deeper on Numba\n",
    "Let's understand a little better how Numba works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple math operation\n",
    "def add(a, b):\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jit the add funtion\n",
    "add_jit = jit()(add)\n",
    "# inspect_types: Report information about the compiled function and the inferred types.\n",
    "add_jit.inspect_types()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Returns an empty string, but why? What else is missing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_jit(1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_jit.inspect_types()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_jit(1., 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_jit.inspect_types()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect types will list all input types that our jitted function has been compiled for!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will this work?\n",
    "print(add_jit('ab', 'c'))\n",
    "add_jit.inspect_types()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define a custom type (class) with an add method\n",
    "\n",
    "class Point:\n",
    "    def __init__(self, x = 0, y = 0):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    \n",
    "    # For nice printing\n",
    "    def __str__(self):\n",
    "        return f'{self.x},{self.y}'\n",
    "    \n",
    "    # Overload + operator for Point\n",
    "    def __add__(self, other):\n",
    "        x = self.x + other.x\n",
    "        y = self.y + other.y\n",
    "        return Point(x, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we add points together in pure python\n",
    "print(Point(1, 2) + Point(3, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# But can we add points in jitted functions?\n",
    "res = add_jit(Point(1,2), Point(3, 4))\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_jit.inspect_types()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numba has two compilation modes, the nopython mode and the pyobject mode. \n",
    "To enable nopython simply pass the argument: `nopython=True` to the jit decorator.\n",
    "\n",
    "Nopython is a subset of python that numba knows how to deal with. Pyobjects ensure that everything will run, but very slowly in some cases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_njit = jit(nopython=True)(add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = add_njit(Point(1,2), Point(3,4))\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default jit will attempt to infer types, if it fails it will not compile the \n",
    "\n",
    "function, but run in python mode. This will not crash, produce correct results, \n",
    "\n",
    "but will not give any performance improvement. \n",
    "\n",
    "With `nopython=True` it will convert this warning to error, and will fail if \n",
    "\n",
    "numba cannot infer the variable type. This is often the required behavior, \n",
    "\n",
    "hence `numba.njit` is a synonym for jit(nopython=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global variables and Numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import njit\n",
    "# assume we have a global variable\n",
    "\n",
    "secure_pass = '1234'\n",
    "\n",
    "def get_access(input_pass):\n",
    "    if secure_pass == input_pass:\n",
    "        return 'Access Granted!'\n",
    "    else:\n",
    "        return 'Access Denied!'\n",
    "\n",
    "get_access_jit = njit()(get_access)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_access('1234'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_access_jit('1234'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is time to update the secure password\n",
    "secure_pass = '5678'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_access('5678'))\n",
    "print(get_access_jit('5678'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm, what has happened here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So Numba treats globals as compile-time constants. In Python globals are not constants, which can lead to problems. \n",
    "The solution is to not use globals. Or:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_access_jit.recompile()\n",
    "print(get_access_jit('5678'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `ufuncs` and `vectorize`\n",
    "`ufuncs` or universal functions are functions that operate on ndarrays in an elementy-by-element fashion. \n",
    "\n",
    "Numpy uses `ufuncs` to allow for all sorts of array operations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume we want to calculate the standard normal propability distribution function for a given input. \n",
    "\n",
    "$$ PDF(x) = {1 \\over \\sigma \\sqrt{2\\pi} } e^{-{1 \\over 2}({x-\\mu \\over \\sigma})^2 }, \\text{with } \\mu = 0 \\text{ and } \\sigma = 1$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will calculate the PDF of an input element x\n",
    "import math\n",
    "def standard_normal_pdf(x):\n",
    "    return math.exp(-x**2/2.) / math.sqrt(2*math.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_normal_pdf(0.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will this run?\n",
    "import numpy as np\n",
    "x_arr = np.linspace(-4, 4, num=1000000)\n",
    "\n",
    "standard_normal_pdf(x_arr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make it possible to operate on arrays, we just need to annotate the function with the `vectorize` decorator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import vectorize\n",
    "\n",
    "@vectorize\n",
    "def vec_pdf(x):\n",
    "    return math.exp(-x**2/2.) / math.sqrt(2*math.pi)\n",
    "\n",
    "# or alternatively, with the in-line syntax\n",
    "vec_pdf = vectorize()(standard_normal_pdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What if we try with a single element?\n",
    "vec_pdf(0.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or with a vector?\n",
    "vec_pdf(x_arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "# for x in x_arr[::50]:\n",
    "plt.plot(x_arr, vec_pdf(x_arr), color='tab:blue')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal PDF with numpy\n",
    "import numpy as np\n",
    "\n",
    "def numpy_pdf(x):\n",
    "    return np.exp(-x**2/2.) / np.sqrt(2*math.pi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test if the numpy and the vectorized numba implementations agree\n",
    "\n",
    "print(np.allclose(vec_pdf(x_arr), numpy_pdf(x_arr)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal PDF unrolled loop\n",
    "\n",
    "def unrolled_pdf(x_arr):\n",
    "    ret_arr = np.empty_like(x_arr)\n",
    "    for i in range(len(x_arr)):\n",
    "        ret_arr[i] = vec_pdf(x_arr[i])\n",
    "    return ret_arr\n",
    "\n",
    "jit_unrolled_pdf = njit()(unrolled_pdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No Numba, should be really slow, never try this\n",
    "unrolled_time = %timeit -o unrolled_pdf(x_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With Numba\n",
    "jit_time = %timeit -o jit_unrolled_pdf(x_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With Numpy\n",
    "numpy_time = %timeit -o numpy_pdf(x_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With Numba, with vectorize\n",
    "vec_time = %timeit -o vec_pdf(x_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic Parallelization with Numba\n",
    "\n",
    "With Numba, you can easily parallelize jitted functions.\n",
    " \n",
    "There are two ways to do this:\n",
    "1. Passing the `target=parallel` argument to the `vectorize` decorator.\n",
    "2. Passing the `parallel=True` argument to the `jit` or `njit` decorators.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On top of vectorize, we can also parallelize the compiled machine code!\n",
    "parallel_vec_pdf = vectorize(['float32(float32)', 'float64(float64)'],\n",
    "                             target='parallel')(standard_normal_pdf)\n",
    "# Only with a signature list we can use the target='parallel' kwarg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_vec_time = %timeit -o parallel_vec_pdf(x_arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import njit\n",
    "parallel_jit_pdf = njit(parallel=True)(unrolled_pdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_jit_time = %timeit -o parallel_jit_pdf(x_arr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact automatic parallelization is not that simple. We need to make sure there are no interloop dependencies. We can do this by the special parallel `range` generator provided by numba, called `prange`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import prange\n",
    "@njit(parallel=True)\n",
    "def parallel_jit_pdf(x_arr):\n",
    "    ret_arr = np.empty_like(x_arr)\n",
    "    for i in prange(len(x_arr)):\n",
    "        ret_arr[i] = vec_pdf(x_arr[i])\n",
    "    return ret_arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_jit_time = %timeit -o parallel_jit_pdf(x_arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's report all the collected timings\n",
    "\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "rows = []\n",
    "rows.append(['unrolled', unrolled_time.average, 1])\n",
    "rows.append(['jit', jit_time.average, rows[-1][1]/jit_time.average])\n",
    "rows.append(['vec', vec_time.average, rows[-1][1]/vec_time.average])\n",
    "rows.append(['numpy', numpy_time.average, rows[-1][1]/numpy_time.average])\n",
    "rows.append(['parallel_jit', parallel_jit_time.average,\n",
    "            rows[-1][1]/parallel_jit_time.average])\n",
    "rows.append(['parallel_vec', parallel_vec_time.average,\n",
    "            rows[-1][1]/parallel_vec_time.average])\n",
    "\n",
    "\n",
    "\n",
    "table = PrettyTable(['Version', 'Avg. Time (sec)', 'Relative Improvement'])\n",
    "table.align = 'l'\n",
    "# table.border = False\n",
    "for r in rows:\n",
    "    r[1] = np.round(r[1], 4)\n",
    "    r[2] = np.round(r[2], 3)\n",
    "\n",
    "    table.add_row(r)\n",
    "print(table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Numba you can easily run operations in parallel on your multicore machine!\n",
    "\n",
    "Since it is so simple and efficient, we should always use it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_arr = np.array([-1., 1.])\n",
    "\n",
    "%timeit vec_pdf(y_arr)\n",
    "%timeit parallel_vec_pdf(y_arr)\n",
    "%timeit parallel_jit_pdf(y_arr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    " \n",
    "* Never unroll loops in normal Python, use Numpy instead. \n",
    "* Just by adding the @jit (or @njit) line we can get great performance gains!\n",
    "* Both @vectorize and @jit are easy to parallelize, for further improvement in multicore machines. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "<br/><br/>\n",
    "<br/><br/>\n",
    "<br/><br/>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional example, Polynomial equation solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try another example, calculating the solution of a second order polynomial equation:\n",
    "$$ x_{1,2} = {-b \\pm \\sqrt{b^2 - 4ac} \\over 2a} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import njit, prange, vectorize\n",
    "\n",
    "def unrolled_discriminant(A, B, C):\n",
    "    X = np.empty_like(A)\n",
    "    for i in range(len(A)):\n",
    "        X[i] = (-B[i] + math.sqrt(abs(B[i]**2 - 4 * A[i] * C[i])) ) / (2*A[i])\n",
    "    return X\n",
    "\n",
    "@njit(parallel=True)\n",
    "def unrolled_explicitely_parallel_discriminant(A, B, C):\n",
    "    X = np.empty_like(A)\n",
    "    for i in prange(len(A)):\n",
    "        X[i] = (-B[i] + math.sqrt(abs(B[i]**2 - 4 * A[i] * C[i]))) / (2*A[i])\n",
    "    return X\n",
    "\n",
    "def numpy_discriminant(A, B, C):\n",
    "    return (-B + np.sqrt(np.abs(B**2 - 4 * A * C)))/(2 * A)\n",
    "\n",
    "def discriminant(a, b, c):\n",
    "    return (-b + math.sqrt(abs(b**2 - 4 * a * c))) / (2*a)\n",
    "\n",
    "\n",
    "jit_discriminant = njit()(unrolled_discriminant)\n",
    "vec_discriminant = vectorize()(discriminant)\n",
    "parallel_vec_disciminant = vectorize('float64(float64, float64, float64)', target='parallel')(discriminant)\n",
    "parallel_jit_discriminant = njit(parallel=True)(numpy_discriminant)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_arr = np.random.uniform(1, 2, 5000000)\n",
    "b_arr = np.random.uniform(0, 1, 5000000)\n",
    "c_arr = np.random.uniform(-2, -1, 5000000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, let's benchmark all the versions of our function to figure out which performs best!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unrolled_time = %timeit -o unrolled_discriminant(a_arr, b_arr, c_arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_time = %timeit -o numpy_discriminant(a_arr, b_arr, c_arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jit_time = %timeit -o jit_discriminant(a_arr, b_arr, c_arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_time = %timeit -o vec_discriminant(a_arr, b_arr, c_arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_vec_time = %timeit -o parallel_vec_disciminant(a_arr, b_arr, c_arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_jit_time = %timeit -o parallel_jit_discriminant(a_arr, b_arr, c_arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unrolled_explicitely_parallel_time = %timeit -o unrolled_explicitely_parallel_discriminant(a_arr, b_arr, c_arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "rows = []\n",
    "rows.append(['unrolled', unrolled_time.average, 1])\n",
    "rows.append(['numpy', numpy_time.average, rows[-1][1]/numpy_time.average])\n",
    "rows.append(['jit', jit_time.average, rows[-1][1]/jit_time.average])\n",
    "rows.append(['vec', vec_time.average, rows[-1][1]/vec_time.average])\n",
    "rows.append(['parallel_vec', parallel_vec_time.average, rows[-1][1]/parallel_vec_time.average])\n",
    "rows.append(['parallel_jit', parallel_jit_time.average, rows[-1][1]/parallel_jit_time.average])\n",
    "rows.append(['unrolled_explicitely_parallel', unrolled_explicitely_parallel_time.average,\n",
    "            rows[-1][1]/unrolled_explicitely_parallel_time.average])\n",
    "\n",
    "table = PrettyTable(['Version', 'Avg. Time (sec)', 'Relative Improvement'])\n",
    "table.align = 'l'\n",
    "# table.border = False\n",
    "for r in rows:\n",
    "    r[1] = np.round(r[1], 4)\n",
    "    r[2] = np.round(r[2], 3)\n",
    "\n",
    "    table.add_row(r)\n",
    "print(table)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "79ab8fd01a8cec42884b8b2a5d7fb4751c5402d97e9e61d151ed5c6a6352873c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
